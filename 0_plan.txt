kroki:
mysl przewodnia - zacznij od czegos prostego i pozniej komplikuj!
trenowanie modelu w weekkend + predykcja modelu 
GIT!
jak bedzie dobrze dzialalo to mozna to zwiekszyc stosujac levarowanie

0. utils -> wczytanie odpowiednich pakietow
1. get data -> stworzenie folderu i zapis danych do folderu
2. label data (w tym optymalizacja) -> raportu i ustalenie finalnych parametrow + wystawienie finalnych lagels
3. generowanie featerow -> zapis ABT
4. kroswalidacja + trenowanie -> zapis modelu
5. predykcja -> decyzja
6. 

99. skopiuj skrypty do dziennego katalogu - czy potrzebne skoro jest GIT?


na pozniej:
[done] * przyjrze sie dollar
* przerobic target evaluate - jezeli jest sygnal do sprzedazy to sprzedajemy po Open dnia nastepnego, jezeli jest sygnal kupna to analogicznie. Moze trzeba wyliczyc nowa zmienna oparta na dzienna stope zwrotu?
[done] * fbprophet
    https://pythondata.com/forecasting-time-series-data-with-prophet-part-1/
    stworzyc funkcje ktora bedziie zwracac liste datadla ktorych trzeba wyliczyc prophet
* Klasteryzacja OHLC (przedzielenie przez Close da wymiar R3)
[done] * Keltner Channel: https://www.investopedia.com/terms/k/keltnerchannel.asp
[done] * Countdown Indicator: https://medium.com/geekculture/the-countdown-indicator-a-new-tool-in-contrarian-trading-3648a5c20d5
* Fractal Indicator: https://www.investopedia.com/terms/f/fractal.asp
[done] * dodac do podsumowania roczne stopy zwrotu
* dodac do podsumowania maksymalne obsuniecie
    https://www.investopedia.com/terms/m/maximum-drawdown-mdd.asp
    https://quant.stackexchange.com/questions/18094/how-can-i-calculate-the-maximum-drawdown-mdd-in-python/18101
[done] * majac grnice gorna i dolna (Bollinger bands, Donchain channel itp) policzyc srednia z (close - low) / (high - low)
* na potrzeby checku warto zobaczyc jak model ocenia poczatek pandemii (lub wogole okresy pandemii)
* logowanie
* czy w labels_generate parametr smooth nie dawac tylko na przod?
* Buffet Indicator
    https://www.parkiet.com/Analizy/304129967-WykresDnia-Wskaznik-Buffetta-alarmuje.html
    https://finance.yahoo.com/news/buffett-indicator-202500577.html?guccounter=1&guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&guce_referrer_sig=AQAAAHJ_hNx3JA-vEPNVKWR8g8qK-Dkn4qFx-SWUukDlUGgCjlrPtdHJmw2zObdunYK1EJD9D6reZ8dIY_HTK5eFqpqqhVLDDbkkX2gYaOJVj0sY-tD1JWrRQTorI4Kkaa6-tW2FsbMrVusmim3tb7ju1NSeIwOByT7P5FAmzrEY0h_w
    https://finance.yahoo.com/news/buffett-indicator-202500577.html
        https://finance.yahoo.com/quote/%5EW5000?p=%5EW5000
    - dane: https://www.longtermtrends.net/market-cap-to-gdp-the-buffett-indicator/    
* wskaznik sentymentu
    https://medium.com/swlh/using-python-to-download-sentiment-data-for-financial-trading-1c44346926e2
* Breadth Indicator - liczba akcji wzrostowych
* zastanowicc sie czy optymalizowac param_atr_base (teraz na sztywnon param_atr_base = 14)
* wielkie krachy (wybrane w USA): https://www.youtube.com/watch?v=VDBUPjD9ekA&t=6s
    1929-1932; wielki kryzys; czas wyjscia 15 lat
    2000; banka internetowa (NASDAQ); czas wyjscia 15 lat
    2007; globalny kryzys finansowy (S&P 500); czas wyjscia 4 lata
    2020; pandemia Covid-19; czas wyjscia 6 m-czy
    jeszcze wykres finansowej fortecy
    https://bithub.pl/opinie/najwieksze-krachy-na-gieldzie-a-sp-500-czy-czeka-nas-kolejna-fala-spadkow/    
[done] * dodanie OHLC do outputu predykcji do XLSX
[done] * wyplucie predykcji do TXT
[done] * sprawdzic czy przy tworzeniu ABT (laczeniu danych) nie tworza sie braki
[done] * usrednienie predykcji target (np. spojrzenie na ostatnie 3 dni - jezeli w kazdym dniu byl target = 1 to wtedy dopiero predykcja 1)
[done] * predykcja
[done] * weryfikacja czy ewaluacja jest poprawna (na pryzkladzie OOT)
[done] * RL bez upsample
[done] * konfiguracja ktore modele sa trenowanie
[done] * konfiguracja czy trenowanie czy tylko predykcja
[done] * konfiguracjja wyboru OOT (data odciecia)
[done] * ensembling (srednia arytmetyczna, wazona F1 score OOF/OOT, voting)

* https://machinelearningmastery.com/gradient-boosting-with-scikit-learn-xgboost-lightgbm-and-catboost/
** https://machinelearningmastery.com/configure-gradient-boosting-algorithm/
** https://machinelearningmastery.com/light-gradient-boosted-machine-lightgbm-ensemble/
** https://xgboost.readthedocs.io/en/latest/parameter.html#parameters-for-tree-booster
[done] * uwzglednij prowizje przy nadawaniu label
[done] * XGB ma jakis parametr dla niezbilansowanego zbioru
[done] * Usuniecie duplikatów, wysoko korelacji – filtr na podstawie macierzy korelacji
[done] * ramka danych t, t-1, t-2 itd. unormowane do t - można też jakos usredniac. Do rozwazenia w sieciach neuronowych

=======================
info z pracy
Korzystamy ze standardów PEP8: https://www.python.org/dev/peps/pep-0008
Ø  Ograniczamy długość znaków w jednej linii
Ø  Stosujemy snake_case (https://en.wikipedia.org/wiki/Snake_case) dla nazw zmiennych i nazw funkcji
Ø  Wszystkie funkcje i zmienne zapisujemy pełnymi, angielskimi nazwami (nie używamy trzyliterowych skrótów poza szczególnymi wyjątkami: np. pd, lgd, max, min) - https://chrisdone.com/posts/german-naming-convention/

Dokumentujemy każdą z funkcji:
Ø  Stosujemy konwencję ze scikit-learn-a (https://scikit-learn.org/stable/developers/contributing.html#contribute-documentation )
Ø  Używamy przypisania typów do argumentów: https://docs.python.org/3/library/typing.html oraz zwracanego typu np. create_feature_dictionary(features: list) -> dict:
Ø  Dla argumentów pomocniczych (takich, które nie przekazują danych, a jedynie parametry) używamy wartości domyślnych https://www.geeksforgeeks.org/default-arguments-in-python/
Ø  Pod każdą z definicji zmiennych dodajemy stringa z jej opisem, zawierającym jej krótki opis, oraz argumenty i zwracany obiekt
Staramy się obsługiwać wyjątki tak, aby dawać bardziej czytelną informację (https://docs.python.org/3/tutorial/errors.html)